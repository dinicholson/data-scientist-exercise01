{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "workingDir = 'C:\\\\Users\\\\Doug\\\\Documents\\\\GitHub\\\\data-scientist-exercise01\\\\exploration'\n",
    "os.chdir(workingDir)\n",
    "\n",
    "conf_file = '.\\\\specs.yaml'\n",
    "Sample_Size = 10000\n",
    "\n",
    "export_dir = '.\\\\tmp\\\\'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "#os.chdir(workingDir)\n",
    "import collections\n",
    "import matplotlib\n",
    "import io\n",
    "import sys\n",
    "import operator\n",
    "\n",
    "import nbformat as nbf\n",
    "from IPython.core.display import HTML\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact, interactive,fixed\n",
    "from IPython.display import Javascript, display,HTML\n",
    "from ipywidgets import widgets, VBox\n",
    "import ipywidgets\n",
    "import IPython\n",
    "from IPython.display import clear_output\n",
    "import scipy.stats as stats\n",
    "from statsmodels.graphics.mosaicplot import mosaic\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import os\n",
    "import errno\n",
    "import seaborn as sns\n",
    "from string import Template\n",
    "from functools import partial\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Utility Classes\n",
    "from ConfUtility import * \n",
    "from ReportGeneration import *\n",
    "from UniVarAnalytics import *\n",
    "from MultiVarAnalytics import *\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#DEBUG=0\n",
    "\n",
    "font={'family':'normal','weight':'normal','size':8}\n",
    "matplotlib.rc('font',**font)\n",
    "matplotlib.rcParams['figure.figsize'] = (12.0, 5.0)\n",
    "matplotlib.rc('xtick', labelsize=9) \n",
    "matplotlib.rc('ytick', labelsize=9)\n",
    "matplotlib.rc('axes', labelsize=10)\n",
    "matplotlib.rc('axes', titlesize=10)\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "if not os.path.exists(export_dir):\n",
    "    os.makedirs(export_dir)\n",
    "    \n",
    "def gen_report(conf_md,conf_code, md, code, filename):\n",
    "    ReportGeneration.write_report(conf_md, conf_code, md, code, report_name=filename)\n",
    "\n",
    "def translate_code_commands(cell, exported_cols, composite=False):    \n",
    "    new_code_store = []\n",
    "    exported_cols = [each for each in exported_cols if each!='']   \n",
    "    for each in exported_cols:       \n",
    "        w,x,y = each.split(',')\n",
    "        with open('log.txt','w') as fout:\n",
    "            fout.write('Processing call for the column {}'.format(each))\n",
    "        temp=cell[0]\n",
    "\n",
    "        new_line = temp.replace('interactive','apply').replace(\n",
    "            \"df=fixed(df)\",\"df\").replace(\"filename=fixed(filename)\",\"'\"+ReportMagic.var_files+\"'\").replace(\n",
    "            \"col1=w1\",\"'\"+w+\"'\").replace(\"col2=w2\",\"'\"+x+\"'\").replace(\"col3=w3\",\"'\"+y+\"'\").replace(\n",
    "            \"col3=fixed(w3)\",\"'\"+y+\"'\").replace(\n",
    "            \"Export=w_export\",\"False\").replace(\"conf_dict=fixed(conf_dict)\",\"conf_dict\")       \n",
    "        new_line = new_line.replace(\"df,\",\"[df,\")\n",
    "        new_line = new_line[:len(new_line)-1]+\"])\"\n",
    "        new_code_store.append(new_line)        \n",
    "    return new_code_store\n",
    "\n",
    "def add_to_report(section='', task=''):\n",
    "    print 'Section {}, Task {} added for report generation'.format(section ,task)\n",
    "\n",
    "def trigger_report(widgets,export_cols_file, output_report, no_widgets=1, md_text=''):\n",
    "    exported_cols = []\n",
    "    with open(export_cols_file,'r') as fin:\n",
    "        for each in fin:\n",
    "            each = each.strip()\n",
    "            if each and not each.isspace():\n",
    "                exported_cols.append(each)\n",
    "                \n",
    "    exported_cols = list(set(exported_cols))\n",
    "    conf_md, conf_code, md, code=%show_report \n",
    "    md = md_text\n",
    "    cell = code\n",
    "    new_code_store = translate_code_commands(cell,exported_cols)\n",
    "    gen_report(conf_md,conf_code, md, new_code_store, filename=export_dir+output_report)\n",
    "    \n",
    "def silentremove(filename):\n",
    "    try:\n",
    "        os.remove(filename)\n",
    "    except OSError as e: # this would be \"except OSError, e:\" before Python 2.6\n",
    "        if e.errno != errno.ENOENT: # errno.ENOENT = no such file or directory\n",
    "            raise # re-raise exception if a different error occured\n",
    "\n",
    "def handle_change(value):\n",
    "    w_export.value=False\n",
    "\n",
    "def getWidgetValue(w):\n",
    "    w_value = ''\n",
    "    try:\n",
    "        w_value = w.value\n",
    "    except:\n",
    "        pass    \n",
    "    return w_value\n",
    "\n",
    "def handle_export(widget, w1, w2, w3, export_filename='temp.ipynb',md_text=''):    \n",
    "    print 'handle_export called'\n",
    "    w1_value, w2_value, w3_value = \\\n",
    "        getWidgetValue(w1),getWidgetValue(w2),getWidgetValue(w3)\n",
    "    st = ','.join(str(each) for each in [w1_value, w2_value, w3_value])\n",
    "    with open(filename,'a') as fout:\n",
    "        fout.write(st+'\\n')\n",
    "    trigger_report(w1_value, filename, export_filename, False, md_text=md_text)  \n",
    "    \n",
    "            \n",
    "\n",
    "conf_dict = ConfUtility.parse_yaml(conf_file)\n",
    "\n",
    "# Read in data from local file or SQL server\n",
    "if 'DataSource' not in conf_dict:\n",
    "    df=pd.read_csv(conf_dict['DataFilePath'], skipinitialspace=True)\n",
    "else:\n",
    "    import pyodbc\n",
    "    cnxn = pyodbc.connect('driver=ODBC Driver 11 for SQL Server;server={};database={};Uid={};Pwd={}'.format(\n",
    "            conf_dict['Server'], conf_dict['Database'],conf_dict['Username'],conf_dict['Password']))\n",
    "    df = pd.read_sql(conf_dict['Query'],cnxn)\n",
    "\n",
    "# Making sure that we are not reading any extra column\n",
    "df = df[[each for each in df.columns if 'Unnamed' not in each]]\n",
    "\n",
    "# Sampling Data if data size is larger than 10k\n",
    "df0 = df # df0 is the unsampled data. Will be used in data exploration and analysis where sampling is not needed\n",
    "         # However, keep in mind that your final report will always be based on the sampled data. \n",
    "if Sample_Size < df.shape[0]:\n",
    "    df = df.sample(Sample_Size)\n",
    "\n",
    "# change float data types\n",
    "if 'FloatDataTypes' in conf_dict:   \n",
    "    for col_name in conf_dict['FloatDataTypes']:\n",
    "        df[col_name] = df[col_name].astype(float)      \n",
    "        \n",
    "# Getting the list of categorical columns if it was not there in the yaml file\n",
    "if 'CategoricalColumns' not in conf_dict:\n",
    "    conf_dict['CategoricalColumns'] = list(set(list(df.select_dtypes(exclude=[np.number]).columns)))\n",
    "\n",
    "# Getting the list of numerical columns if it was not there in the yaml file\n",
    "if 'NumericalColumns' not in conf_dict:\n",
    "    conf_dict['NumericalColumns'] = list(df.select_dtypes(include=[np.number]).columns)    \n",
    "\n",
    "# Exclude columns that we do not need\n",
    "if 'ColumnsToExclude' in conf_dict:\n",
    "    conf_dict['CategoricalColumns'] = list(set(conf_dict['CategoricalColumns'])-set(conf_dict['ColumnsToExclude']))\n",
    "    conf_dict['NumericalColumns'] = list(set(conf_dict['NumericalColumns'])-set(conf_dict['ColumnsToExclude']))\n",
    "\n",
    "# Ordering the categorical variables according to the number of unique categories\n",
    "filtered_cat_columns = []\n",
    "temp_dict = {}\n",
    "for cat_var in conf_dict['CategoricalColumns']:\n",
    "    temp_dict[cat_var] = len(np.unique(df[cat_var]))\n",
    "sorted_x = sorted(temp_dict.items(), key=operator.itemgetter(0), reverse=True)\n",
    "conf_dict['CategoricalColumns'] = [x for (x,y) in sorted_x]\n",
    "\n",
    "ConfUtility.dict_to_htmllist(conf_dict,['Target','CategoricalColumns','NumericalColumns'])\n",
    "def custom_head(df,NoOfRows):\n",
    "    return HTML(df.head(NoOfRows).style.set_table_attributes(\"class='table'\").render())\n",
    "i = interact(custom_head,df=fixed(df0), NoOfRows=ipywidgets.IntSlider(min=0, max=30, step=1, \\\n",
    "                                                                     value=5, description='Number of Rows'))\n",
    "print 'The data has {} Rows and {} columns'.format(df0.shape[0],df0.shape[1])\n",
    "col_names = ','.join(each for each in list(df.columns))\n",
    "print(\"The column names are:\" + col_names)\n",
    "print(\"The types of columns are:\")\n",
    "df.dtypes\n",
    "def num_missing(x):\n",
    "    return len(x.index)-x.count()\n",
    "\n",
    "def num_unique(x):\n",
    "    return len(np.unique(x))\n",
    "\n",
    "temp_df = df0.describe().T\n",
    "missing_df = pd.DataFrame(df0.apply(num_missing, axis=0)) \n",
    "missing_df.columns = ['missing']\n",
    "unq_df = pd.DataFrame(df0.apply(num_unique, axis=0))\n",
    "unq_df.columns = ['unique']\n",
    "types_df = pd.DataFrame(df0.dtypes)\n",
    "types_df.columns = ['DataType']\n",
    "summary_df = temp_df.join(missing_df).join(unq_df).join(types_df)\n",
    "summary_df\n",
    "col_names = list(types_df.index) #Get all col names\n",
    "num_cols = len(col_names)\n",
    "index = range(num_cols)\n",
    "cat_index = []\n",
    "for i in index: #Find the indices of columns in Categorical columns\n",
    "    if col_names[i] in conf_dict['CategoricalColumns']:\n",
    "        cat_index.append(i)\n",
    "summary_df_cat = missing_df.join(unq_df).join(types_df.iloc[cat_index], how='inner') #Only summarize categorical columns\n",
    "summary_df_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "i = apply(InteractionAnalytics.nnc_relation, [df,                                                conf_dict, 'over_50k', '', '', False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank variables based on linear relationships with reference variable (on sampled data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "i = apply(InteractionAnalytics.rank_associations, [df,                                                 conf_dict, 'over_50k', '5', '5', False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interaction between categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "i = apply(InteractionAnalytics.rank_associations, [df,                                                 conf_dict, 'over_50k', 'education_level', '', False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "i = apply(InteractionAnalytics.rank_associations, [df,                                                 conf_dict, 'over_50k', '5', '5', False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore interactions between two numerical variables and a categorical variable (on sampled data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "i = apply(InteractionAnalytics.rank_associations, [df,                                                 conf_dict, 'over_50k', 'education_level', '', False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "i = apply(InteractionAnalytics.rank_associations, [df,                                                 conf_dict, 'over_50k', '5', '5', False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "i = apply(InteractionAnalytics.rank_associations, [df,                                                 conf_dict, 'age', 'hours_week', 'over_50k', False])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "name": "_merged"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
